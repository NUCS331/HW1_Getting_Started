{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Getting start with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework one is supposed to be starter into python, image processing and linear algebra. You'll learn how to implement functions as external python-files, how to import and use them into jupyter notebooks.\n",
    "\n",
    "A big focus is also in using matplotlib since visualization skills is one of the key skills you'll need to aquire during 331. Computational Photogrpahy included \"computation\" and \"photogrpahy\". Quantifying data and results with numbers is important, however, photography - by its name - implies that it is a visual discipline. We're evaluating images and it's utterly important to visualize every little step in the pipeline you are developping.\n",
    "\n",
    "In this course we're not only interested in seeing input data and the proccessed results, we want to see what you're doing inside the pipeline. Please keep this is mind when you're designing the report for each homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few notes on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the first time you've ever used a jupyter notebook, please refer to the following tutorials to get started:\n",
    "\n",
    "## Introduction to Python\n",
    "1. Nice Documentation that shows you the essentials: https://www.w3schools.com/python/default.asp\n",
    "2. Interactive tutorial in browser:  https://www.learnpython.org/\n",
    "\n",
    "## Introduction to Jupyter\n",
    "Jupyter Notebooks have emerged to be an essential tool for many data scientists and researchers. We recommend using Jupyter to test out small snippets of codes, etc., but theoretically, you could do most of your homework purely withing Jupyter. \n",
    "1. https://realpython.com/jupyter-notebook-introduction/\n",
    "2. Video Tutorial: https://www.youtube.com/playlist?list=PL1m-6MPBNAZfF-El7BzqaOrCrTBRgH1Nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few packages to load that might come in handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is doing linear algebra and all the math for us\n",
    "import random # Random to create random numbers\n",
    "import matplotlib.pyplot as plt # matplotlib allows us to plot images and graphs\n",
    "# Information on autoreload which will be important to update your modules \n",
    "# when you change them so that they work in the jupyter notebook\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "import ipytest.magics\n",
    "ipytest.autoconfig()\n",
    "# you might need to install py through: pip install py and pip install -U pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the functions that you will have to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.code as code\n",
    "import src.optics as optics\n",
    "import src.imageprocessing as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the functions in code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.sum_numbers(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.multiply_numbers(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.create_add_matrix(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.indexing_aggregation([1,2,4,4,5], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4,7],[2,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = code.matrix_inverse(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this is the actual inverse\n",
    "np.matmul(A,A_inv)\n",
    "# The should be a matrix with only ones on the diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a specific test like here:\n",
    "We have started to implement PyTests for the homeworks, however we're not completely there to have autograding incorporated into the class. However. some of the pytest might be useful to help you debug your codes to check if your subfunctions are working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a specific test\n",
    "ipytest.run('-s', filename='tests/test_netid.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a specific function in the test file\n",
    "ipytest.run('-s', filename='tests/test_assignment.py::test_indexing_aggregation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all tests at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipytest.run('-s', filename='tests/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with some very simple image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of HW you will learn basic image processing tasks. There are several functions you have to implement and we have provided simple pytests that are checking that the functions are doing the job.\n",
    "\n",
    "However, when you visualize these images you should immediately see if somethings goes wrong or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image neeeds to be implemented\n",
    "I = ip.load_image(\"images/northwestern.jpg\") \n",
    "\n",
    "\n",
    "print(type(I)) # Should be <class 'numpy.ndarray'>\n",
    "print(I.dtype) # Should be float32\n",
    "print(I.shape) # Should be (1200, 2265, 3)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I)\n",
    "plt.title(\"Image of Northwestern and Chicago Skyline\")\n",
    "\n",
    "save_fig_as_png(\"Northwestern_Skyline\")\n",
    "\n",
    "# Check the test for this function works\n",
    "ipytest.run('-s', filename='tests/test_skyline.py::test_load_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images, should be of size (250, 1000, 3)\n",
    "I_Chicago = ip.crop_chicago_from_northwestern(I)\n",
    "\n",
    "print(type(I_Chicago)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_Chicago.dtype) # Should be float32\n",
    "print(I_Chicago.shape) # Should be (250, 1000, 3)\n",
    "\n",
    "plt.imshow(I_Chicago)\n",
    "plt.title(\"Skyline of Chicago\")\n",
    "\n",
    "save_fig_as_png(\"Chicago_Skyline\")\n",
    "\n",
    "# Check the test for this function works\n",
    "ipytest.run('-s', filename='tests/test_skyline.py::test_crop_chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_chicago_gray = ip.convert_rgb2gray(I_Chicago)\n",
    "\n",
    "print(type(I_chicago_gray)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_chicago_gray.dtype) # Should be float32\n",
    "print(I_chicago_gray.shape) # Should be (250, 1000) or (250, 1000,1)\n",
    "\n",
    "plt.imshow(I_chicago_gray,cmap='gray')\n",
    "plt.title(\"Skyline of Chicago in Gray\")\n",
    "\n",
    "save_fig_as_png(\"Chicago_Skyline_gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_downsampled = ip.downsample_by_scale_factor(I_chicago_gray,8)\n",
    "\n",
    "print(type(I_downsampled)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_downsampled.dtype) # Should be float32\n",
    "print(I_downsampled.shape) # Should be for downsampling facto of 8 (31, 125)\n",
    "\n",
    "plt.imshow(I_downsampled,cmap='gray')\n",
    "plt.title(\"A downsampled version of the Chicago skyline\")\n",
    "\n",
    "save_fig_as_png(\"Chicago_Skyline_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# This should show the chicago skyline a subplot (2 x 2) for diufferent scale factors\n",
    "ip.plot_chicago_skyline(I_chicago_gray)\n",
    "\n",
    "save_fig_as_png(\"Chicago_Skyline_downsampled_multiple_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Do the same of an image of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've implemented basic image processing tools, please download an image of your choice and do the same experiments as we've done here (i.e. image loading, cropping, converting from RGB to gray and show a subplot with different downsampling scales.\n",
    "<br>\n",
    "Please include these images in your project report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will play around with simple image processing algorithms. In particular, we will load a png image of dog which has a transparent background and we will overlay it ontop of a nature landscape.\n",
    "\n",
    "First, we will play around with resizing and rotating images. Afterwards we will put our functions into a larger framework which again is composed of several functions.\n",
    "\n",
    "The purpose of this assignment to get familair with numpy, skimage, cv2 and other packages which will come in handy in the future assignments.\n",
    "\n",
    "After we've learned basic image processing tools, we will use the blur estimation functions we have discussed in Lecture 2 to estimate different blur kernels for background and foreground respectively. We hence, simulate the effect of potrait photos you often see in DLSR cameras or modern smartphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to implement a function that can load an image. You can use any file oder image read class that you can find online.\n",
    "However, note that we don't just want to have 3 channels for RGB (Red-Green-Blue), but a fourth channel, called alpha, that controls the transparency of each pixel. \n",
    "An alpha value of $0$ would correspond to no transparency, an alpha value of $1$ would show no transparency.\n",
    "Luckiluy, matplotlib knows how to deal with an alpha channel automatically and takes care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.load_image('images/dog2.png')\n",
    "print(I_dog.shape) # Should be (995, 800, 4)\n",
    "print(I_dog.dtype) # Should show 'float32'\n",
    "print(I_dog.max()) # Shoud be normalized to 1\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"The original image as it is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pad Dog Image with Zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are padding the dog images because we might need to blur the dog image later. In order to not have boundary effects when blurring we're padding with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 100\n",
    "I_dog_padded = ip.pad_image(I_dog,pad_size)\n",
    "# Confirm that shape has changed\n",
    "print(I_dog_padded.shape) # (Should be 1195, 1000, 4) with pad_size = 100\n",
    "print(I_dog_padded.dtype) # Should still be a float32\n",
    "\n",
    "plt.imshow(I_dog_padded)\n",
    "plt.title(\"Padded Dog Image\")\n",
    "\n",
    "save_fig_as_png(\"dog_cropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resize Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change the size of the dog image flexible to make a \"nicer\" composition of our final image. \n",
    "Sidenote: If we know the size of an average dog we can actually scale it so that it fits well with our actual camera paramters that we will choose later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.rescale(I_dog_padded,0.9)\n",
    "\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"Rescaled Dog\")\n",
    "\n",
    "save_fig_as_png(\"dog_rescaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the background image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are loading the background image. If everything is implemented well, we should be able to reuse the function we already for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "print(I_canyon.shape) # should have 3 channels in the image\n",
    "print(I_canyon.dtype) # should be float32\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canyon image doesn't yet have an alpha channel. We need to add another axis. You'll have to implement a small method called \"add_alpha_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "print(I_canyon.shape) # should have 4 channels in the image now, including the alpha channel\n",
    "print(I_canyon.dtype) # should be float32\n",
    "plt.imshow(I_canyon)\n",
    "save_fig_as_png(\"canyon_with_alpha_channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(I_dog)\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_height, dog_width, _  = I_dog.shape\n",
    "print(dog_height,dog_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the alpha channel of the dog to make sur that it looks good\n",
    "mask = I_dog[:,:,3] #this should give a black and white image of the outline of the dog\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.title(\"Alpha Channel of dog\")\n",
    "plt.colorbar()\n",
    "\n",
    "save_fig_as_png(\"dog_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_dog.shape)\n",
    "print(mask.shape) # the dog should have 4 channels, one of them being the alpha channel which you can see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_canyon.shape)\n",
    "print(I_dog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog.shape > I_canyon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dog shape: \" + str(I_dog.shape))\n",
    "print(\"Background shape: \" + str(I_canyon.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 150\n",
    "y0 = 400\n",
    "I_new = ip.overlay_two_images(I_canyon,I_dog,[x0,y0])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_new)\n",
    "plt.title(\"Overlayed Image without any focus settings\")\n",
    "\n",
    "save_fig_as_png(\"dog_overlayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's to do some Image Formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be implementing a simpler version of the DoF simulator \n",
    "from https://dofsimulator.net/en/\n",
    "\n",
    "Please go there and play around with it to get a feeling for how DoF works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Include some of the image from the DOF simulator in your report and show us that you've develooped a feeling for depth-of-field and defocus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the formulas from the lecture that you have to remember:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$\\frac{b}{D}=\\frac{|i' - i|}{i'}$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$b=\\frac{D}{i'}\\cdot |i' - i| =D | \\frac{f(o-o'}{o'(o-f)} | $ </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{1}{i} + \\frac{1}{o} = \\frac{1}{f} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're using a DLSR with a Canon EF-mount for our simulation\n",
    "Information on Flange-Focal distance: https://en.wikipedia.org/wiki/Flange_focal_distance\n",
    "<br>\n",
    "Information on https://en.wikipedia.org/wiki/Canon_EF_lens_mount\n",
    "<br>\n",
    "Full frame Camera: https://en.wikipedia.org/wiki/Full-frame_digital_SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All units will be in mm\n",
    "m = 1000 # m in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size_mm = np.array([24,36]) # mm\n",
    "print(sensor_size_mm)\n",
    "flange_focal_distance = 44.00 # mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Length\n",
    "focal_length = 50 # mm\n",
    "# F-number\n",
    "N = 4\n",
    "# Aperture Diameter\n",
    "D = focal_length/N # mm\n",
    "# Focus Distance\n",
    "o_foc = 1.5*m # mm\n",
    "# Object Distance\n",
    "o_obj = 1.5*m # mm\n",
    "# Let's assume that the background is really far away, e.g. 1km away. \n",
    "o_background = 1000*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_object = optics.calc_blur_radius(focal_length,D,o_foc,o_obj)\n",
    "print(\"Blur Radius: \" + str(b_object) + \" mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_background =  optics.calc_blur_radius(focal_length,D,o_foc,o_background)\n",
    "print(\"Blur Radius: \" + str(b_background)+ \" mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the approximate blur radii for different image distances. \n",
    "What we have to do next, is the define how large the images actually are, so that we know what is the physical size of a pixel of the 2 images.\n",
    "\n",
    "This will help us to convert into how much we have to blur both images to approximate the correct amount of optical blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_background = optics.crop_background_image_sensor_ratio(sensor_size_mm,I_canyon)\n",
    "plt.imshow(I_background)\n",
    "\n",
    "save_fig_as_png(\"image_cropped_sensor_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define how large the images are\n",
    "\n",
    "angle_of_view = optics.calc_angle_of_view(sensor_size_mm,focal_length)\n",
    "print(\"Angle of view: \" + str(angle_of_view) + \" deg\")\n",
    "field_of_view_object = optics.calc_field_of_view(sensor_size_mm,o_obj,focal_length)\n",
    "print(\"Field of View (Object): \" + str(field_of_view_object/m) + \" m\" )\n",
    "field_of_view_background = optics.calc_field_of_view(sensor_size_mm,o_background,focal_length)\n",
    "print(\"Field of View (Background) \" + str(field_of_view_background/m) + \" m\" )\n",
    "\n",
    "I_dog_real_height = 0.5*m\n",
    "I_dog_real_width = I_dog.shape[1]/I_dog.shape[0] * I_dog_real_height\n",
    "print(I_dog_real_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size_background = sensor_size_mm[0]/I_background.shape[0]\n",
    "pixel_size_foreground = sensor_size_mm[0]/I_dog.shape[0]\n",
    "\n",
    "print(\"Pixel Size - Background: \" + str(pixel_size_background))\n",
    "print(\"Pixel Size - Foreground: \" + str(pixel_size_foreground))\n",
    "\n",
    "\n",
    "blur_radius_background_pixel = b_background/pixel_size_background\n",
    "blur_radius_foreground_pixel = b_object/pixel_size_foreground\n",
    "\n",
    "print(\"Blur Radius Background: \" + str(blur_radius_background_pixel))\n",
    "print(\"Blur Radus Foreground: \" + str(blur_radius_foreground_pixel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate how much 1 pixel for background and foreground is in SI [mm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create disk-like filter footprint with given radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a radial distance map. It should be 0 in the center and the values increase radially symmetric\n",
    "# If the dimension is e.g. 100 pixels, the maximum value would be sqrt(2)*50 which is around 74\n",
    "\n",
    "R = optics.create_radial_distance_map(100)\n",
    "plt.imshow(R)\n",
    "plt.colorbar()\n",
    "print(R.shape)\n",
    "\n",
    "save_fig_as_png(\"radial_distance_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to calculate the point-spread-function\n",
    "# Read more on PSFs here: https://en.wikipedia.org/wiki/Point_spread_function\n",
    "\n",
    "PSF = optics.gaussian_psf(R,blur_radius_background_pixel)\n",
    "\n",
    "print(PSF.sum()) # should sum up to 1, otherwise energy is lost\n",
    "print(PSF.shape) # should be the same size as the radial map you generated earlire\n",
    "plt.imshow(PSF)\n",
    "plt.colorbar()\n",
    "\n",
    "save_fig_as_png(\"gaussian_psf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_filtered = optics.convolve_image(I_background,PSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_filtered)\n",
    "\n",
    "save_fig_as_png(\"filtered_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a good place where you want to center the second image\n",
    "x0 = 150\n",
    "y0 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_new = ip.overlay_two_images(im_filtered,I_dog,[x0,y0])\n",
    "plt.imshow(I_new)\n",
    "\n",
    "save_fig_as_png(\"dog_overlayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Create your own defocus image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have all the ingredients, you can try the same with another pair of images of your choice. Try to be creative.\n",
    "\n",
    "If you're image of the foreground is not segmented, you can use external tools (e.g. paint.net) and extract the object. Then you can save the image with an transparent background, e.g. as .png.\n",
    "\n",
    "Include the results of the canyon and the dog as well your own images in the final result.\n",
    "\n",
    "Play around with several imaging parameters, such as focal length, focus distance etc. to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

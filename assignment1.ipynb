{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Getting start with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1 is supposed to be a slightly more sophisticated starter homework into python, image processing, and linear algebra. You'll revise how to implement functions as external python-files and import and use them in jupyter notebooks.\n",
    "\n",
    "A big focus is also on learning how to use matplotlib since visualization skills are key skills you will need to acquire during 331. Computational photography includes two words, \"computation\" and \"photography.\" Of course, quantifying data and results with numbers is essential, however, photography - by its name - implies that it is a visual discipline. We're evaluating images, and it's utterly important to meticulously visualize every little step in the pipeline you are developing.\n",
    "\n",
    "In this course, we're not only interested in seeing input data and the processed results, but we also want to know what you're doing inside the pipeline. Please keep this in mind when you're designing the report for each homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few notes on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this class is the first time you've ever used Python and Jupyter Notebook, please refer to the following tutorials before starting the homework.\n",
    "\n",
    "## Introduction to Python\n",
    "1. Excellent Documentation that shows you the essentials: https://www.w3schools.com/python/default.asp\n",
    "2. Interactive tutorial in browser:  https://www.learnpython.org/\n",
    "\n",
    "## Introduction to Jupyter\n",
    "In recent years, Jupyter Notebook/Labs have emerged as an essential tool for many data scientists and researchers. We recommend using Jupyter to test out small snippets of codes inside Jupyter Cells until they function correctly. Once tested out inside Jupyter, you can copy the complete function body over to the external .py cell for extensive testing.\n",
    "\n",
    "Here are a few references on Jupyter Notebook that might be helpful if you're new to it:\n",
    "1. https://realpython.com/jupyter-notebook-introduction/\n",
    "2. Video Tutorial: https://www.youtube.com/playlist?list=PL1m-6MPBNAZfF-El7BzqaOrCrTBRgH1Nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to complete this assignment\n",
    "<span style=\"color:white\">*To complete the assignment, you will solve 2 problems, each of which consists of a coding task and a writing task as outlined inside this notebook. To achieve a passing grade, you must successfully complete all of the coding tasks, AND you must write up your results in a well-documented report.* </span>   \n",
    "\n",
    "## <span style=\"color:red\">Coding Tasks: </span>\n",
    "You will implement functions in the following python files:\n",
    "- src/code.py\n",
    "- src/imageprocessing.py\n",
    "- src/optics.py\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Writing Tasks: </span>\n",
    "You will write up your results in a latex report that sh\n",
    "ould document:\n",
    "\n",
    "1) the problem statement for the homework\n",
    "2) the methods that you used to solve the problem\n",
    "3) the results you achieved, including figures generated in this notebook after you have completed the coding tasks. \n",
    "\n",
    "Please refer to the latex template for your writeups as indicated on the homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning: \n",
    "\n",
    "We're going to use matplotlib to plot a lot, and we're going to want to use colormap/colorbars to next to our plots, but they get buggy, and aren't usually the correct size to the graph. Use this following solution to fix it!\n",
    "\n",
    "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few packages to load that might come in handy for the homework\n",
    "\n",
    "# Note: If any of those packages cannot be loaded, simply install them using \n",
    "# PIP or Conda. Just google \"pip install PACKAGE name\", and you'll find more information on\n",
    "# how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is doing linear algebra and all the math for us\n",
    "import random # Random to create random numbers\n",
    "import matplotlib.pyplot as plt # matplotlib allows us to plot images and graphs\n",
    "import PIL # PIL is an image library\n",
    "import cv2 # cv2 is an image processing library\n",
    "import skimage # skimage is another image procssing library\n",
    "import skimage.transform\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on autoreload which will be important to update your modules \n",
    "# when you change them so that they work in the jupyter notebook\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not using PyTests in Fall 2020 much since we are currently developing \n",
    "# an autograding framework for all homeworks. However, unit testing \n",
    "# (e.g. with pytet/ipytest) are a great skill to have when developing software.\n",
    "\n",
    "# Please import these packages to see how they work\n",
    "import pytest\n",
    "import ipytest\n",
    "import ipytest.magics\n",
    "ipytest.autoconfig()\n",
    "# you might need to install py through pip install py and pip install -U pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the functions that you will have to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 different files inside the src folder: code, image processing, and optics\n",
    "# All 3 files contain functions that you will have to implement to pass this assignment\n",
    "\n",
    "# This notebook will guide you chronically through all functions, and whenever a function is not yet implemented, you will run into a \"RaiseNoteImplemented\" error\n",
    "# If this error occurs, navigate inside your Jupyter Lab to the python file \n",
    "# and read the function description that you'll have to implement then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.code as code\n",
    "import src.optics as optics\n",
    "import src.imageprocessing as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the functions in code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a reminder, let's quickly reimplement the functions from HW0.\n",
    "# We'll use them to showcase how the pytest-package is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.sum_numbers(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.multiply_numbers(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.create_add_matrix(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code.indexing_aggregation([1,2,4,4,5], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4,7],[2,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = code.matrix_inverse(A)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this is the actual inverse\n",
    "np.matmul(A,A_inv)\n",
    "# The should be a matrix with only ones on the diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a specific test like here:\n",
    "As stated above, we have started to implement PyTests for the homeworks. However, we're not completely there to have auto-grading incorporated into the class. However, some of the pytests might be useful to help you debug your codes to check if your subfunctions are working well. \n",
    " \n",
    "Unit testing is a great skill to have in Software Development and PyTest, together with iPyTest is an excellent resource for it. The following lines are showing how they can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a specific test\n",
    "ipytest.run('-s', filename='tests/test_netid.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a specific function in the test file\n",
    "ipytest.run('-s', filename='tests/test_assignment.py::test_indexing_aggregation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all tests at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipytest.run('-s', filename='tests/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with some very simple image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of homework 1 you will learn basic image processing tasks. There are several functions you have to implement, and we have provided simple pytests that are checking that the functions are doing the job.\n",
    "\n",
    "However, once you try to visualize these images, you should immediately see if something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image neeeds to be implemented\n",
    "I = ip.load_image(\"images/northwestern.jpg\") \n",
    "\n",
    "# According to the function description \n",
    "# following properties must be true when printed\n",
    "print(type(I)) # Should be <class 'numpy.ndarray'>\n",
    "print(I.dtype) # Should be float32\n",
    "print(I.shape) # Should be (1200, 2265, 3) for the chicago image\n",
    "print(I.max()) # Should be 1.0 (since it is scaled) for the chicago image\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I)\n",
    "plt.title(\"Image of Northwestern and Chicago Skyline\")\n",
    "\n",
    "ip.save_fig_as_png(\"Northwestern_Skyline\")\n",
    "\n",
    "# Check the test for this function works\n",
    "ipytest.run('-s', filename='tests/test_skyline.py::test_load_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images, should be of size (250, 1000, 3)\n",
    "I_Chicago = ip.crop_chicago_from_northwestern(I)\n",
    "\n",
    "print(type(I_Chicago)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_Chicago.dtype) # Should be float32\n",
    "print(I_Chicago.shape) # Should be (250, 1000, 3)\n",
    "\n",
    "plt.imshow(I_Chicago)\n",
    "plt.title(\"Skyline of Chicago\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline\")\n",
    "\n",
    "# Check the test for this function works\n",
    "ipytest.run('-s', filename='tests/test_skyline.py::test_crop_chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_chicago_gray = ip.convert_rgb2gray(I_Chicago)\n",
    "\n",
    "print(type(I_chicago_gray)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_chicago_gray.dtype) # Should be float32\n",
    "print(I_chicago_gray.shape) # Should be (250, 1000) or (250, 1000,1)\n",
    "\n",
    "plt.imshow(I_chicago_gray,cmap='gray')\n",
    "plt.title(\"Skyline of Chicago in Gray\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_downsampled = ip.downsample_by_scale_factor(I_chicago_gray,8)\n",
    "\n",
    "print(type(I_downsampled)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_downsampled.dtype) # Should be float32\n",
    "print(I_downsampled.shape) # Should be for downsampling facto of 8 (31, 125)\n",
    "\n",
    "plt.imshow(I_downsampled,cmap='gray')\n",
    "plt.title(\"A downsampled version of the Chicago skyline\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# This should show the chicago skyline a subplot (2 x 2) for diufferent scale factors\n",
    "ip.plot_chicago_skyline(I_chicago_gray)\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled_multiple_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implemet the same procedure for your own image</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've implemented basic image processing tools, please download an image of your choice and do the same experiments as we've done here. I.e., that you should do image loading, cropping, converting from RGB to gray and show a subplot with different downsampling scales.\n",
    "<br>\n",
    "Please include these images in your project report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing Tasks: Answer a few questions</span>\n",
    "1. What happens when you downsample an image? Are there different ways how to downsample an image? D quick google literature research and cite your resource.\n",
    "2. If you downsample an image, are you losing information? Explain in your own words why information is lost!\n",
    "3. Are there images where no information is lost when an image is downsampled? I.e., are there image that can be restored from a downsampled version? Nyquist Sampling Theorem is a keyword that you could google here.\n",
    "4. When you transformed an image from RBB to Gray, we didn't just ask you to take the mean value. Can you explain why I used a slightly more complicated formula by weighing the different channels differently? Google search will give you an answer; please describe it in your own words and cite your resource.\n",
    "5. What is the difference between uint8, uint16, float32,float64? What advantages/disadvantages might come with using different file formats? What is the dynamic range you can achieve? When do you think this could this become important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Processing : Overlay Images</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will play around with simple image processing algorithms. In particular, we will first load an image of a dog with a transparent background. Subsequently, we will overlay this image on top of a picture of a natural landscape.\n",
    "\n",
    "First, we will play around with resizing and rotating images. Afterward, we will put our functions into a broader framework, which again is composed of several parts.\n",
    "\n",
    "This assignment aims to familiarize you with NumPy, skimage, cv2, and other packages that will come in handy in the future assignments.\n",
    "\n",
    "After we've learned these basic image processing tools, we will use the blur estimation functions discussed in Lecture 2 to estimate different blur kernels for background and foreground. We then simulate the effect of portrait photos that appear naturally in DLSR cameras or are simulated for nicer effects in modern smartphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to revisit the function that can load an image that you should have already implemented at the beginning of the assignment.\n",
    "\n",
    "However, note that we are now dealing not only with 3 channels for RGB (Red-Green-Blue) but with a fourth channel, called alpha, which controls the transparency in each pixel.\n",
    "\n",
    "An alpha value of $0$ would correspond to no transparency, an alpha value of $1$ would show no transparency.\n",
    "\n",
    "Luckily, matplotlib knows how to automatically deal with an alpha channel and take care of this when we want to display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.load_image('images/dog2.png')\n",
    "print(I_dog.shape) # Should be (995, 800, 4)\n",
    "print(I_dog.dtype) # Should show 'float32'\n",
    "print(I_dog.max()) # Shoud be normalized to 1\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"The original image as it was saved\")\n",
    "# You should see a dog with a white background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pad Dog Image with Zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are padding the dog images because we might need to blur the dog image later. In order to not have boundary effects when blurring we're padding with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 100\n",
    "I_dog_padded = ip.pad_image(I_dog,pad_size)\n",
    "# Confirm that shape has changed\n",
    "print(I_dog_padded.shape) # (Should be 1195, 1000, 4) with pad_size = 100\n",
    "print(I_dog_padded.dtype) # Should still be a float32\n",
    "\n",
    "plt.imshow(I_dog_padded)\n",
    "plt.title(\"Padded Dog Image\")\n",
    "# You should see the same image of the dog but now there should be more white areas around the dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resize Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change the size of the dog image flexible to make a \"nicer\" composition of our final image. \n",
    "Sidenote: If we know the size of an average dog we can actually scale it so that it fits well with our actual camera paramters that we will choose later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.rescale(I_dog_padded,0.9)\n",
    "\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"Rescaled Dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the background image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are loading the background image. If everything is implemented well, we should be able to reuse the function we already for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canyon image doesn't yet have an alpha channel. We need to add another axis. You'll have to implement a small method called \"add_alpha_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(I_dog)\n",
    "plt.subplot(122)\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_height, dog_width, _  = I_dog.shape\n",
    "print(dog_height,dog_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0\n",
    "y0 = 0\n",
    "I_overlay = I_canyon\n",
    "print(I_overlay.shape)\n",
    "I_overlay = I_overlay[x0:x0+dog_height,y0:y0+dog_width,:]\n",
    "plt.imshow(I_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the alpha channel of the dog to make sur that it looks good\n",
    "mask = I_dog[:,:,3]\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.title(\"Alpha Channel of dog\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_dog.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_canyon.shape)\n",
    "print(I_dog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog.shape > I_canyon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dog shape: \" + str(I_dog.shape))\n",
    "print(\"Background shape: \" + str(I_canyon.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 150\n",
    "y0 = 400\n",
    "I_new = ip.overlay_two_images(I_canyon,I_dog,[x0,y0])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_new)\n",
    "plt.title(\"Overlayed Image without any focus settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implement Dog overlayed with Yosemite</span>\n",
    "\n",
    "At this point you should see a dog that sits infront of a yosemite landscape. If this doesn't look well, please play around with the function we've asked you to implement. Don't proceed until this works well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Formation of a DLSR with Defocus </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be implementing a simpler version of the DoF simulator \n",
    "from https://dofsimulator.net/en/\n",
    "\n",
    "Please go there and play around with it to get a feeling for how DoF works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the formulas from the lecture that you'll need for this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$\\frac{b}{D}=\\frac{|i' - i|}{i'}$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$b=\\frac{D}{i'}\\cdot |i' - i| =D | \\frac{f(o-o'}{o'(o-f)} | $ </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{1}{i} + \\frac{1}{o} = \\frac{1}{f} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're using a DLSR with a Canon EF-mount for our simulation\n",
    "Information on Flange-Focal distance: https://en.wikipedia.org/wiki/Flange_focal_distance\n",
    "<br>\n",
    "Information on https://en.wikipedia.org/wiki/Canon_EF_lens_mount\n",
    "<br>\n",
    "Full frame Camera: https://en.wikipedia.org/wiki/Full-frame_digital_SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All units will be in mm\n",
    "m = 1000 # m in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size_mm = np.array([24,36]) # mm\n",
    "print(sensor_size_mm)\n",
    "flange_focal_distance = 44.00 # mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Length\n",
    "focal_length = 50 # mm\n",
    "# F-number\n",
    "N = 4\n",
    "# Aperture Diameter\n",
    "D = focal_length/N # mm\n",
    "# Focus Distance\n",
    "o_foc = 1.5*m # mm\n",
    "# Object Distance\n",
    "o_obj = 1.5*m # mm\n",
    "# Let's assume that the background is really far away, e.g. 1km away. \n",
    "o_background = 1000*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_object = optics.calc_blur_radius(focal_length,D,o_foc,o_obj)\n",
    "print(\"Blur Radius: \" + str(b_object) + \" mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_background =  optics.calc_blur_radius(focal_length,D,o_foc,o_background)\n",
    "print(\"Blur Radius: \" + str(b_background)+ \" mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the approximate blur radii for different image distances. \n",
    "What we have to do next, is the define how large the images actually are, so that we know what is the physical size of a pixel of the 2 images.\n",
    "\n",
    "This will help us to convert into how much we have to blur both images to approximate the correct amount of optical blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_background = optics.crop_background_image_sensor_ratio(sensor_size_mm,I_canyon)\n",
    "plt.imshow(I_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define how large the images are\n",
    "\n",
    "angle_of_view = optics.calc_angle_of_view(sensor_size_mm,focal_length)\n",
    "print(\"Angle of view: \" + str(angle_of_view) + \" deg\")\n",
    "field_of_view_object = optics.calc_field_of_view(sensor_size_mm,o_obj,focal_length)\n",
    "print(\"Field of View (Object): \" + str(field_of_view_object/m) + \" m\" )\n",
    "field_of_view_background = optics.calc_field_of_view(sensor_size_mm,o_background,focal_length)\n",
    "print(\"Field of View (Background) \" + str(field_of_view_background/m) + \" m\" )\n",
    "\n",
    "I_dog_real_height = 0.5*m\n",
    "I_dog_real_width = I_dog.shape[1]/I_dog.shape[0] * I_dog_real_height\n",
    "print(I_dog_real_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size_background = sensor_size_mm[0]/I_background.shape[0]\n",
    "pixel_size_foreground = sensor_size_mm[0]/I_dog.shape[0]\n",
    "\n",
    "print(\"Pixel Size - Background: \" + str(pixel_size_background))\n",
    "print(\"Pixel Size - Foreground: \" + str(pixel_size_foreground))\n",
    "\n",
    "\n",
    "blur_radius_background_pixel = b_background/pixel_size_background\n",
    "blur_radius_foreground_pixel = b_object/pixel_size_foreground\n",
    "\n",
    "print(\"Blur Radius Background: \" + str(blur_radius_background_pixel))\n",
    "print(\"Blur Radus Foreground: \" + str(blur_radius_foreground_pixel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate how much 1 pixel for background and foreground is in SI [mm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create disk-like filter footprint with given radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a radial distance map. It should be 0 in the center and the values increase radially symmetric\n",
    "# If the dimension is e.g. 100 pixels, the maximum value would be sqrt(2)*50 which is around 74\n",
    "\n",
    "R = optics.create_radial_distance_map(100)\n",
    "plt.imshow(R)\n",
    "plt.colorbar()\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to calculate the point-spread-function\n",
    "# Read more on PSFs here: https://en.wikipedia.org/wiki/Point_spread_function\n",
    "\n",
    "PSF = optics.gaussian_psf(R,blur_radius_background_pixel)\n",
    "\n",
    "print(PSF.sum()) # should sum up to 1, otherwise energy is lost\n",
    "print(PSF.shape) # should be the same size as the radial map you generated earlire\n",
    "plt.imshow(PSF)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to conolve the background image with the Point Spread Function. \n",
    "# Please implement the convolution. Note that you're allowed to use external packages\n",
    "\n",
    "im_filtered = optics.convolve_image(I_background,PSF)\n",
    "\n",
    "print(I_background.shape)\n",
    "print(im_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a good place where you want to center the second image\n",
    "x0 = 150\n",
    "y0 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_new = ip.overlay_two_images(im_filtered,I_dog,[x0,y0])\n",
    "plt.imshow(I_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Tasks: Answer a few questions</span>\n",
    "\n",
    "By now, you have implemented all the ingredients for the Defocus-simulator. It is time to try this with another pair of images of your choice. Try to be creative and make an exciting assembly. You can use your own photos or pictures from Google for this task.\n",
    "\n",
    "If your foreground image (i.e., the replacement for the dog) is not segmented, you can use external tools (e.g., paint.net) and extract it. Then you can save the image with a transparent background, e.g., as .png. \n",
    "\n",
    "Include the results of the canyon/dog example and your creation in the final report. \n",
    "\n",
    "### <span style=\"color:orange\">Task: </span>\n",
    "Play around with different parameters of the camera. E.g., you can play around with focal length, the aperture, the distance to the background. \n",
    "Bonus points: You can even try to focus the camera away from the object so that both object and background are defocused. Include your findings in your final report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing Tasks: Answer a few questions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your **abstract** should summarize in 3-4 sentences what you've learned in this exercise. \n",
    "Your **introduction** should give a small opening on how images are formed. \n",
    "\n",
    "Here are a few questions that your report should answer:\n",
    "\n",
    "1. What is the aspect ratio of a Camera? What is the sensor size? Can be a camera sensor be arbitrarily large or small?\n",
    " - Think of your smartphone camera sensor. Is it preferable to have a small sensor or a large sensor?\n",
    " - Think of the pixel pitch (size of a pixel). Does it make sense to have a 1GigaPixel resolution sensor of the size of a smartphone? To answer this, you can e.g., read through this interview ( https://www.theverge.com/21427188/marc-levoy-interview-adobe-smartphone-computational-photography-vergecast) by Marc Levoy on recent trends in the commercial sensing market.\n",
    "2. What is the aperture?\n",
    " - What is the effect of a large vs. a small aperture? \n",
    " - Think in terms of Depth-of-Field, but also in terms of light-budget and how it might affect motion artifacts, etc.\n",
    "3. What is the focal length? When would you use a small focal length when a large focal length?\n",
    "4. What is the flange focal distance? Why is it so crucial for the imaging system? What can happen if the camera system is only slightly misaligned?\n",
    "5. Explain the hyperfocal distance in your own words!\n",
    "6. Assume that an image of an object is blurred due to an out-of-focus blur. Is the same blur applied to each region (i.e., it is translation invariant)? What kind of object (or image scenario) would you need that the blur is constant throughout the image? For a general 3d scene, explain how the distance of several objects (at different depths) might contribute to the image in terms of varying blur sizes.\n",
    "7. Why did we zero-pad the dog image ? Think about what could happen if you have large convolution kernels (PSF) if you do not take care of the boundaries? What are possible ways to deal with boundaries when doing convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

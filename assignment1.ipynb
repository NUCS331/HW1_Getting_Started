{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Getting start with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1 is supposed to be a slightly more sophisticated starter homework into python, image processing, and linear algebra. You'll revise how to implement functions as external python-files and import and use them in jupyter notebooks.\n",
    "\n",
    "A big focus is also on learning how to use matplotlib since visualization skills are key skills you will need to acquire during 331. Computational photography includes two words, \"computation\" and \"photography.\" Of course, quantifying data and results with numbers is essential, however, photography - by its name - implies that it is a visual discipline. We're evaluating images, and it's utterly important to meticulously visualize every little step in the pipeline you are developing.\n",
    "\n",
    "In this course, we're not only interested in seeing input data and the processed results, but we also want to know what you're doing inside the pipeline. Please keep this in mind when you're designing the report for each homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few notes on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this class is the first time you've ever used Python and Jupyter Notebook, please refer to the following tutorials before starting the homework.\n",
    "\n",
    "## Introduction to Python\n",
    "1. Excellent Documentation that shows you the essentials: https://www.w3schools.com/python/default.asp\n",
    "2. Interactive tutorial in browser:  https://www.learnpython.org/\n",
    "\n",
    "## Introduction to Jupyter\n",
    "In recent years, Jupyter Notebook/Labs have emerged as an essential tool for many data scientists and researchers. We recommend using Jupyter to test out small snippets of codes inside Jupyter Cells until they function correctly. Once tested out inside Jupyter, you can copy the complete function body over to the external .py cell for extensive testing.\n",
    "\n",
    "Here are a few references on Jupyter Notebook that might be helpful if you're new to it:\n",
    "1. https://realpython.com/jupyter-notebook-introduction/\n",
    "2. Video Tutorial: https://www.youtube.com/playlist?list=PL1m-6MPBNAZfF-El7BzqaOrCrTBRgH1Nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to complete this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To complete the assignment, you will solve 2 problems, each of which consists of a coding task and a writing task as outlined inside this notebook. To achieve a passing grade, you must successfully complete all of the coding tasks, AND you must write up your results in a well-documented report.*   \n",
    "\n",
    "## <span style=\"color:red\">Coding Tasks: </span>\n",
    "You will implement functions in the following python files:\n",
    "- src/imageprocessing.py\n",
    "- src/optics.py\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Writing Tasks: </span>\n",
    "You will write up your results in a latex report that should document:\n",
    "\n",
    "1. the rough problem statement for the homework\n",
    " - What was this homework about? What did you learn?\n",
    "2. The methods that you used to solve the problem\n",
    " - What was the problem in your opinion ? \n",
    " - Introduce the image formation problem?\n",
    "3. The results you achieved, including figures generated in this notebook after you have completed the coding tasks. \n",
    "\n",
    "Please refer to the latex template for your writeups as indicated on the homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note for matlotlib: \n",
    "\n",
    "We're going to use matplotlib to plot a lot, and we're going to want to use colormap/colorbars to next to our plots, but they get buggy, and aren't usually the correct size to the graph. Use this following solution to fix it!\n",
    "\n",
    "https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning: Possibly Import of additional packages might be necessary\n",
    "\n",
    "You might need to import the packages in the src-files as well if you need them. If you want to use additional packages, feel free to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few packages to load that might come in handy for the homework\n",
    "\n",
    "# Note: If any of those packages cannot be loaded, simply install them using \n",
    "# PIP or Conda. Just google \"pip install PACKAGE name\", and you'll find more information on\n",
    "# how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is doing linear algebra and all the math for us\n",
    "import random # Random to create random numbers\n",
    "import matplotlib.pyplot as plt # matplotlib allows us to plot images and graphs\n",
    "import PIL # PIL is an image library\n",
    "import cv2 # cv2 is an image processing library\n",
    "import skimage # skimage is another image procssing library\n",
    "import skimage.transform\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on autoreload which will be important to update your modules \n",
    "# when you change them so that they work in the jupyter notebook\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the functions that you will have to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 different files inside the src folder: image processing, and optics\n",
    "# All 3 files contain functions that you will have to implement to pass this assignment\n",
    "\n",
    "# This notebook will guide you chronically through all functions, and whenever a function is not yet implemented, you will run into a \"RaiseNoteImplemented\" error\n",
    "# If this error occurs, navigate inside your Jupyter Lab to the python file \n",
    "# and read the function description that you'll have to implement then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.optics as optics\n",
    "import src.imageprocessing as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with some very simple image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of homework 1 you will learn basic image processing tasks. There are several functions you have to implement, and we have provided simple pytests that are checking that the functions are doing the job.\n",
    "\n",
    "However, once you try to visualize these images, you should immediately see if something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-65d81e15b010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load image neeeds to be implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images/northwestern.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# According to the function description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# following properties must be true when printed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ip' is not defined"
     ]
    }
   ],
   "source": [
    "# Load image neeeds to be implemented\n",
    "I = ip.load_image(\"images/northwestern.jpg\") \n",
    "\n",
    "# According to the function description \n",
    "# following properties must be true when printed\n",
    "print(type(I)) # Should be <class 'numpy.ndarray'>\n",
    "print(I.dtype) # Should be float32\n",
    "print(I.shape) # Should be (1200, 2265, 3) for the chicago image\n",
    "print(I.max()) # Should be 1.0 (since it is scaled) for the chicago image\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I)\n",
    "plt.title(\"Image of Northwestern and Chicago Skyline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3b80d87d805c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This is a function that will save the current output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# You find the description in ImageProcessing.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_fig_as_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Northwestern_Skyline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/NUCS331/HW1_Getting_Started/src/imageprocessing.py\u001b[0m in \u001b[0;36msave_fig_as_png\u001b[0;34m(figtitle)\u001b[0m\n\u001b[1;32m     24\u001b[0m     '''\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is a function that will save the current output \n",
    "# You find the description in ImageProcessing.py\n",
    "ip.save_fig_as_png(\"Northwestern_Skyline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images, should be of size (250, 1000, 3)\n",
    "I_Chicago = ip.crop_chicago_from_northwestern(I)\n",
    "\n",
    "print(type(I_Chicago)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_Chicago.dtype) # Should be float32\n",
    "print(I_Chicago.shape) # Should be (250, 1000, 3)\n",
    "\n",
    "plt.imshow(I_Chicago)\n",
    "plt.title(\"Skyline of Chicago\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_chicago_gray = ip.convert_rgb2gray(I_Chicago)\n",
    "\n",
    "print(type(I_chicago_gray)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_chicago_gray.dtype) # Should be float32\n",
    "print(I_chicago_gray.shape) # Should be (250, 1000) or (250, 1000,1)\n",
    "\n",
    "plt.imshow(I_chicago_gray,cmap='gray')\n",
    "plt.title(\"Skyline of Chicago in Gray\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_downsampled = ip.downsample_by_scale_factor(I_chicago_gray,8)\n",
    "\n",
    "print(type(I_downsampled)) # Should be <class 'numpy.ndarray'>\n",
    "print(I_downsampled.dtype) # Should be float32\n",
    "print(I_downsampled.shape) # Should be for downsampling facto of 8 (31, 125)\n",
    "\n",
    "plt.imshow(I_downsampled,cmap='gray')\n",
    "plt.title(\"A downsampled version of the Chicago skyline\")\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# This should show the chicago skyline a subplot (2 x 2) for diufferent scale factors\n",
    "ip.plot_chicago_skyline(I_chicago_gray)\n",
    "\n",
    "ip.save_fig_as_png(\"Chicago_Skyline_downsampled_multiple_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implement the same procedure for your own image</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've implemented basic image processing tools, please download an image of your choice and do the same experiments as we've done here. I.e., that you should do image loading, cropping, converting from RGB to gray and show a subplot with different downsampling scales.\n",
    "<br>\n",
    "Please include these images in your project report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing Tasks: Answer a few questions</span>\n",
    "1. What happens when you downsample an image? Are there different ways how to downsample an image? Do a quick google literature research and cite your resource.\n",
    "2. If you downsample an image, are you losing information? Explain in your own words why information is lost!\n",
    "3. Are there images where no information is lost when an image is downsampled? I.e., are there image that can be restored from a downsampled version? Nyquist Sampling Theorem is a keyword that you could google here.\n",
    " - Explain the term aliasing in your own words. This is a concept you should encounter in your literature research. Maybe you can even include a picture that you find online?\n",
    "  - When you upsample your image? What can you do? Are there different methods to achieve this goal?\n",
    "4. When you transformed an image from RGB to Gray, we didn't just ask you to take the mean value. Can you explain why I used a slightly more complicated formula by weighing the different channels differently? Google search will give you an answer; please describe it in your own words and cite your resource.\n",
    "5. What is the difference between uint8, uint16, float32,float64? What advantages/disadvantages might come with using different file formats? What is the dynamic range you can achieve? When do you think this could this become important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Processing : Overlay Images</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will play around with simple image processing algorithms. In particular, we will first load an image of a dog with a transparent background. Subsequently, we will overlay this image on top of a picture of a natural landscape.\n",
    "\n",
    "First, we will play around with resizing and rotating images. Afterward, we will put our functions into a broader framework, which again is composed of several parts.\n",
    "\n",
    "This assignment aims to familiarize you with NumPy, skimage, cv2, and other packages that will come in handy in the future assignments.\n",
    "\n",
    "After we've learned these basic image processing tools, we will use the blur estimation functions discussed in Lecture 2 to estimate different blur kernels for background and foreground. We then simulate the effect of portrait photos that appear naturally in DLSR cameras or are simulated for nicer effects in modern smartphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to revisit the function that can load an image that you should have already implemented at the beginning of the assignment.\n",
    "\n",
    "However, note that we are now dealing not only with 3 channels for RGB (Red-Green-Blue) but with a fourth channel, called alpha, which controls the transparency in each pixel.\n",
    "\n",
    "An alpha value of $0$ would correspond to no transparency, an alpha value of $1$ would be fully transparent.\n",
    "\n",
    "Luckily, matplotlib knows how to automatically deal with an alpha channel and take care of this when we want to display an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.load_image('images/dog2.png')\n",
    "print(I_dog.shape) # Should be (995, 800, 4)\n",
    "print(I_dog.dtype) # Should show 'float32'\n",
    "print(I_dog.max()) # Shoud be normalized to 1\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"The original image as it was saved\")\n",
    "# You should see a dog with a white background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pad Dog Image with Zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are padding the dog images because we might need to blur the dog image later. In order to not have boundary effects when blurring we're padding with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d972ba685775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpad_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mI_dog_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Confirm that shape has changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (Should be 1195, 1000, 4) with pad_size = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Should still be a float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ip' is not defined"
     ]
    }
   ],
   "source": [
    "pad_size = 100\n",
    "I_dog_padded = ip.pad_image(I_dog,pad_size)\n",
    "# Confirm that shape has changed\n",
    "print(I_dog_padded.shape) # (Should be 1195, 1000, 4) with pad_size = 100\n",
    "print(I_dog_padded.dtype) # Should still be a float32\n",
    "\n",
    "plt.imshow(I_dog_padded)\n",
    "plt.title(\"Padded Dog Image\")\n",
    "# You should see the same image of the dog but now there should be more white areas around the dog\n",
    "\n",
    "ip.save_fig_as_png(\"padded_dog_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resize Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change the size of the dog image flexible to make a \"nicer\" composition of our final image. \n",
    "Sidenote: If we know the size of an average dog we can actually scale it so that it fits well with our actual camera paramters that we will choose later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_dog = ip.rescale(I_dog_padded,0.9)\n",
    "\n",
    "\n",
    "plt.imshow(I_dog)\n",
    "plt.title(\"Rescaled Dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the background image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are loading the background image. If everything is implemented well, we should be able to reuse the function we already for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_canyon = ip.load_image('images/yosemite.jpg')\n",
    "# The image is pretty, large we should downscale it for easier processing\n",
    "I_canyon = ip.rescale(I_canyon,0.25)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canyon image doesn't yet have an alpha channel. We need to add another axis. You'll have to implement a small method called \"add_alpha_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_canyon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ca7d99ecfc42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mI_canyon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_alpha_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_canyon' is not defined"
     ]
    }
   ],
   "source": [
    "I_canyon = ip.add_alpha_channel(I_canyon)\n",
    "print(I_canyon.shape)\n",
    "print(I_canyon.dtype)\n",
    "plt.imshow(I_canyon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_dog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-19a3de350d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# your load_image function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI_dog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Alpha Channel of dog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_dog' is not defined"
     ]
    }
   ],
   "source": [
    "# Let us also visualize the alpha channel of the dog to make sur that it looks good/ as expected.\n",
    "# If this doesn't look like a segmentation mask, something is wrong and you need to revisit\n",
    "# your load_image function\n",
    "\n",
    "mask = I_dog[:,:,3]\n",
    "plt.imshow(mask,cmap='gray')\n",
    "plt.title(\"Alpha Channel of dog\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Overlay images of same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_dog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bf6d98d5a346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# First let us rescale the dog image because it is quite large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mI_dog_rescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mI_dog_rescaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_dog' is not defined"
     ]
    }
   ],
   "source": [
    "# First let us rescale the dog image because it is quite large\n",
    "I_dog_rescaled = ip.rescale(I_dog,0.5)\n",
    "I_dog_rescaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_canyon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f21871866d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mI_overlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI_canyon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mI_overlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI_overlay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mI_dog_rescaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mI_dog_rescaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_overlay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_canyon' is not defined"
     ]
    }
   ],
   "source": [
    "# For testing purposes let us crop out an image of the background which has exactly the\n",
    "# Same dimension as the rescaled dog\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "I_overlay = I_canyon\n",
    "I_overlay = I_overlay[x0:x0+I_dog_rescaled.shape[0],y0:y0+I_dog_rescaled.shape[1],:]\n",
    "print(I_overlay.shape)\n",
    "plt.imshow(I_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_overlay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-877de9d9b444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# WARNING: TAKE CARE OF THE BOUNDARIES.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mI_test_overlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_two_images_of_same_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_overlay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI_dog_rescaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# When you visualize this you should now see a Dog with the canyon image in the backgroud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_overlay' is not defined"
     ]
    }
   ],
   "source": [
    "# Now you have to implement a function that overlays to images of the same size\n",
    "# where the second images contains the alpha-channel mask which you need\n",
    "# to account correctly for\n",
    "\n",
    "# WARNING: DO NOT SHRINK THE DOG\n",
    "# WARNING: DO NOT PLACE THE DOG ON TOP OF THE MOUNTAIN\n",
    "# WARNING: TAKE CARE OF THE BOUNDARIES.\n",
    "\n",
    "I_test_overlay = ip.overlay_two_images_of_same_size(I_overlay,I_dog_rescaled)\n",
    "\n",
    "# When you visualize this you should now see a Dog with the canyon image in the backgroud\n",
    "# If this looks weird you'll have to revisit either the load_image function or \n",
    "# the overlay_two_images_of_same_size function that you just implemented\n",
    "plt.imshow(I_test_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay imags of arbitrary sizes\n",
    "Now that we've learned how to overlay two images of the same size, we're going to look into how to overlay two images of arbitrary sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_dog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-81d75d6ced64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# These are some of the image data dimensions. Please think of why this might be problematic. This can help yoi when implementing the overlay function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dog shape: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background shape: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_dog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mI_canyon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_dog' is not defined"
     ]
    }
   ],
   "source": [
    "# These are some of the image data dimensions. Please think of why this might be problematic. This can help yoi when implementing the overlay function\n",
    "\n",
    "print(\"Dog shape: \" + str(I_dog.shape))\n",
    "print(\"Background shape: \" + str(I_canyon.shape))\n",
    "print(I_dog.shape > I_canyon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I_canyon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-cd9a9582afa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mI_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_two_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_canyon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI_dog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I_canyon' is not defined"
     ]
    }
   ],
   "source": [
    "# For the location settings below the dogs feet shut be cut off since the feet would extend over the boundary of the canyon image\n",
    "# This is intened, because otherwise it would appear that the dog is floating in \"air\"\n",
    "# Feel free to play around with the location settings. For the image in your report try to avoid a \"floating\" dog\n",
    "# And have it appears as natural as possible\n",
    "\n",
    "x0 = 150\n",
    "y0 = 400\n",
    "I_new = ip.overlay_two_images(I_canyon,I_dog,[x0,y0])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(I_new)\n",
    "plt.title(\"Overlayed Image without any focus settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task: Implement Dog overlayed with Yosemite</span>\n",
    "\n",
    "At this point you should see a dog that sits infront of a yosemite landscape. If this doesn't look well, please play around with the function we've asked you to implement. Don't proceed until this works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-ea6baa64ab28>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-ea6baa64ab28>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Your final image should look something like this (Pay attention to the paws)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Hint:\n",
    "\n",
    "Your final image should look something like this (Pay attention to the paws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Orange\"> Image Formation of a Camera System (e.g. DLSR) with Defocus </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be implementing a simpler version of the DoF simulator \n",
    "from https://dofsimulator.net/en/\n",
    "\n",
    "Please go there and play around with it to get a feeling for how DoF works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing task: Report a few examples for the DoF Simulator</span>\n",
    "\n",
    "Play around with the DoF Simulator for a few parameters that you find most interesting. Report a few images (together with their parameter) and visualize your finding using Latex subplot (e.g. using subcaption). Don't inlcude one large image per page, but rather come up with a visualization which clearly shows how different parameter affect the the output.\n",
    "\n",
    "A few of those questions will be asked again later in this report. You don't have to answer them twice, rather include your explanations in a nice write-up.\n",
    "\n",
    "1. Focal Length\n",
    " - How does focal length influence the field-of-view?\n",
    " - How does the focal length influence the defocus-blur\n",
    "2. Aperture\n",
    " - What is the influence of the aperture on the defocus ? Can you reduce the blurring totally of the background by changing the values of the aperture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are the formulas from the lecture that you'll need for this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](defocus_blur.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$\\frac{b}{D}=\\frac{|i' - i|}{i'}$</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lens Maker Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{1}{i} + \\frac{1}{o} = \\frac{1}{f} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>$b=\\frac{D}{i'}\\cdot |i' - i| =D | \\frac{f(o-o')}{o'(o-f)} | $ </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing task: Explain the formulas of image formation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not simply answer each question/tasks here in a chronical faction. Try to write a small text with a good writing flow similair to what you what expect in a methods section in a scientific paper.\n",
    "\n",
    "1. Explain each of this equation in your report\n",
    " - Include the formulas and the image in your write up\n",
    " - Define each variable (give them the best scientific name you can find on google for this problem) \n",
    "2. What are the implications of this formula? When do you have large blur, when not?\n",
    "3. How does the focal length $f$ or the aperture $D$ influence the defocus blur?\n",
    "\n",
    "At the end of the report there are a few other questions which go in the similair direction. Consider both the questions here and later when writing your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're using a DLSR with a Canon EF-mount for our simulation\n",
    "Information on Flange-Focal distance: https://en.wikipedia.org/wiki/Flange_focal_distance\n",
    "<br>\n",
    "Information on https://en.wikipedia.org/wiki/Canon_EF_lens_mount\n",
    "<br>\n",
    "Full frame Camera: https://en.wikipedia.org/wiki/Full-frame_digital_SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All units will be in mm\n",
    "m = 1000 # m in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 36]\n"
     ]
    }
   ],
   "source": [
    "sensor_size_mm = np.array([24,36]) # mm\n",
    "print(sensor_size_mm)\n",
    "flange_focal_distance = 44.00 # mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Task:  Adjust the aspect ratio of the image</span>\n",
    "\n",
    "The image of the background has a specific aspect ratio given by the ratio of #pixels in x and y dimension.\n",
    "\n",
    "However, this aspect ratio might not match with the aspect ratio of the camere chip, which is given by actual size of the chip in x and y direction. We have stored these data for a common image format above in the variable sensor_size_mm.\n",
    "\n",
    "Please implement the crop_background_image_sensor_ratio function to align the background image with the actual sensor aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_background = optics.crop_background_image_sensor_ratio(sensor_size_mm,I_canyon)\n",
    "plt.imshow(I_background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some definitions of your optical system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Length\n",
    "focal_length = 50 # mm\n",
    "# F-number\n",
    "N = 4\n",
    "# Aperture Diameter\n",
    "D = focal_length/N # mm\n",
    "# Focus Distance\n",
    "o_foc = 1.5*m # mm\n",
    "# Object Distance\n",
    "o_obj = 1.5*m # mm\n",
    "# Let's assume that the background is really far away, e.g. 1km away. \n",
    "o_background = 1000*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_object = optics.calc_blur_radius(focal_length,D,o_foc,o_obj)\n",
    "print(\"Blur Radius: \" + str(b_object) + \" mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_background =  optics.calc_blur_radius(focal_length,D,o_foc,o_background)\n",
    "print(\"Blur Radius: \" + str(b_background)+ \" mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate blur ratios\n",
    "Now we know the approximate blur radii for different image distances. \n",
    "What we have to do next, is the define how large the images actually are, so that we know what is the physical size of a pixel of the 2 images.\n",
    "\n",
    "This will help us to convert into how much we have to blur both images to approximate the correct amount of optical blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sensor_size_mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9cff408c1138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's define how large the images are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mangular_field_of_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_angular_field_of_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_size_mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfocal_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Angular field of view: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangular_field_of_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" deg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfield_of_view_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_field_of_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_size_mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfocal_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sensor_size_mm' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's define how large the images are\n",
    "\n",
    "angular_field_of_view = optics.calc_angular_field_of_view(sensor_size_mm,focal_length)\n",
    "print(\"Angular field of view: \" + str(angular_field_of_view) + \" deg\")\n",
    "field_of_view_object = optics.calc_field_of_view(sensor_size_mm,o_obj,focal_length)\n",
    "print(\"Field of View (Object): \" + str(field_of_view_object/m) + \" m\" )\n",
    "field_of_view_background = optics.calc_field_of_view(sensor_size_mm,o_background,focal_length)\n",
    "print(\"Field of View (Background) \" + str(field_of_view_background/m) + \" m\" )\n",
    "\n",
    "I_dog_real_height = 0.5*m\n",
    "I_dog_real_width = I_dog.shape[1]/I_dog.shape[0] * I_dog_real_height\n",
    "print(I_dog_real_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size_background = sensor_size_mm[0]/I_background.shape[0]\n",
    "pixel_size_foreground = sensor_size_mm[0]/I_dog.shape[0]\n",
    "\n",
    "print(\"Pixel Size - Background: \" + str(pixel_size_background))\n",
    "print(\"Pixel Size - Foreground: \" + str(pixel_size_foreground))\n",
    "\n",
    "\n",
    "blur_radius_background_pixel = b_background/pixel_size_background\n",
    "blur_radius_foreground_pixel = b_object/pixel_size_foreground\n",
    "\n",
    "print(\"Blur Radius Background: \" + str(blur_radius_background_pixel))\n",
    "print(\"Blur Radus Foreground: \" + str(blur_radius_foreground_pixel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate how much 1 pixel for background and foreground is in unit millimeters [mm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create disk-like filter footprint with given radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a radial distance map. It should be 0 in the center and the values increase radially symmetric\n",
    "# If the dimension is e.g. 100 pixels, the maximum value would be sqrt(2)*50 which is around 74\n",
    "\n",
    "R = optics.create_radial_distance_map(100)\n",
    "plt.imshow(R)\n",
    "plt.colorbar()\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to calculate the point-spread-function\n",
    "# Read more on PSFs here: https://en.wikipedia.org/wiki/Point_spread_function\n",
    "\n",
    "PSF = optics.gaussian_psf(R,blur_radius_background_pixel)\n",
    "\n",
    "print(PSF.sum()) # should sum up to 1, otherwise energy is lost\n",
    "print(PSF.shape) # should be the same size as the radial map you generated earlire\n",
    "plt.imshow(PSF)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to conolve the background image with the Point Spread Function. \n",
    "# Please implement the convolution. Note that you're allowed to use external packages\n",
    "\n",
    "im_filtered = optics.convolve_image(I_background,PSF)\n",
    "\n",
    "print(I_background.shape)\n",
    "print(im_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a good place where you want to center the second image\n",
    "x0 = 150\n",
    "y0 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_new = ip.overlay_two_images(im_filtered,I_dog,[x0,y0])\n",
    "plt.imshow(I_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Tasks: Answer a few questions</span>\n",
    "\n",
    "By now, you have implemented all the ingredients for the Defocus-simulator. It is time to try this with another pair of images of your choice. Try to be creative and make an exciting assembly. You can use your own photos or pictures from Google for this task.\n",
    "\n",
    "If your foreground image (i.e., the replacement for the dog) is not segmented, you can use external tools (e.g., paint.net) and extract it. Then you can save the image with a transparent background, e.g., as .png. \n",
    "\n",
    "Include the results of the canyon/dog example and your creation in the final report. \n",
    "\n",
    "### <span style=\"color:orange\">Task: </span>\n",
    "Play around with different parameters of the camera. E.g., you can play around with focal length, the aperture, the distance to the background. \n",
    "Bonus points: You can even try to focus the camera away from the object so that both object and background are defocused. Include your findings in your final report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing Tasks: Answer a few questions</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your **abstract** should summarize in 3-4 sentences what you've learned in this exercise. \n",
    "Your **introduction** should give a small opening on how images are formed. \n",
    "\n",
    "Here are a few questions that your report should answer.\n",
    "\n",
    "1. What is the aspect ratio of a Camera? What is the sensor size? Can be a camera sensor be arbitrarily large or small?\n",
    " - Think of your smartphone camera sensor. Is it preferable to have a small sensor or a large sensor?\n",
    " - Think of the pixel pitch (size of a pixel). Does it make sense to have a 1GigaPixel resolution sensor of the size of a smartphone? To answer this, you can e.g., read through this interview ( https://www.theverge.com/21427188/marc-levoy-interview-adobe-smartphone-computational-photography-vergecast) by Marc Levoy on recent trends in the commercial sensing market.\n",
    "2. What is the aperture?\n",
    " - What is the effect of a large vs. a small aperture? \n",
    " - Think in terms of Depth-of-Field, but also in terms of light-budget and how it might affect motion artifacts, etc.\n",
    "3. What is the focal length? When would you use a small focal length when a large focal length?\n",
    "4. What is the flange focal distance? Why is it so crucial for the imaging system? What can happen if the camera system is only slightly misaligned?\n",
    "5. Explain the hyperfocal distance in your own words!\n",
    "6. Assume that an image of an object is blurred due to an out-of-focus blur. Is the same blur applied to each region (i.e., it is translation invariant)? What kind of object (or image scenario) would you need that the blur is constant throughout the image? For a general 3d scene, explain how the distance of several objects (at different depths) might contribute to the image in terms of varying blur sizes.\n",
    "7. Why did we zero-pad the dog image ? Think about what could happen if you have large convolution kernels (PSF) if you do not take care of the boundaries? What are possible ways to deal with boundaries when doing convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
